{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "nltk.data.path.append('/Users/moiz/nltk_data')\n",
    "\n",
    "# Load your dataset\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "\n",
    "def preprocess_text(text, method='Lemmatization'):\n",
    "    \"\"\"Enhanced text preprocessing with lowercasing, punctuation removal.\"\"\"\n",
    "    text = text.lower()  # Lowercase text\n",
    "    text = re.sub(r'[\\d\\W]+', ' ', text)  # Remove punctuation and numbers\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    if method == 'stemming':\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(word) for word in tokens]\n",
    "    else:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df['processed_reviews'] = train_df['review'].apply(lambda x: preprocess_text(x))\n",
    "test_df['processed_reviews'] = test_df['review'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.86325\n",
      "Training time: 0.012458086013793945 seconds\n",
      "RandomForestClassifier Accuracy: 0.84925\n",
      "Training time: 22.505813121795654 seconds\n",
      "KNeighborsClassifier Accuracy: 0.72185\n",
      "Training time: 734.6023411750793 seconds\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction - Example with TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train = vectorizer.fit_transform(train_df['processed_reviews'])\n",
    "X_test = vectorizer.transform(test_df['processed_reviews'])\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df['sentiment'])\n",
    "y_test = le.transform(test_df['sentiment'])\n",
    "\n",
    "# Model Training and Evaluation\n",
    "# Example with MultinomialNB and RandomForestClassifier\n",
    "nb_model = MultinomialNB()\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Training and evaluating each model\n",
    "for model in [nb_model, rf_model, knn_model]:\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    print(f\"{model.__class__.__name__} Accuracy:\", accuracy_score(y_test, predictions))\n",
    "    print(f\"Training time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.86715\n",
      "Average cross-validation score for MultinomialNB: 0.86\n",
      "Training time: 55.61999988555908 seconds\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Method - Basic Voting Classifier\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('nb', nb_model),\n",
    "    ('rf', rf_model),\n",
    "    ('knn', knn_model)\n",
    "], voting='hard')\n",
    "\n",
    "start_time = time.time()\n",
    "ensemble.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "ensemble_predictions = ensemble.predict(X_test)\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(y_test, ensemble_predictions))\n",
    "\n",
    "# Cross-validation Example for MultinomialNB\n",
    "scores = cross_val_score(nb_model, X_train, y_train, cv=5)\n",
    "print(\"Average cross-validation score for MultinomialNB: {:.2f}\".format(scores.mean()))\n",
    "print(f\"Training time: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
