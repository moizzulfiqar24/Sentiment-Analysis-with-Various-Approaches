{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/moiz/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/moiz/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package wordnet to /Users/moiz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/moiz/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package punkt to /Users/moiz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/moiz/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "from afinn import Afinn\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# # Ensure you have the necessary NLTK datasets downloaded\n",
    "# nltk.download('sentiwordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('vader_lexicon')\n",
    "# nltk.download('punkt')  # For tokenization\n",
    "# nltk.download('averaged_perceptron_tagger')  # For POS tagging\n",
    "\n",
    "!python3 -m nltk.downloader -d /Users/moiz/nltk_data sentiwordnet\n",
    "!python3 -m nltk.downloader -d /Users/moiz/nltk_data omw-1.4\n",
    "!python3 -m nltk.downloader -d /Users/moiz/nltk_data wordnet\n",
    "!python3 -m nltk.downloader -d /Users/moiz/nltk_data vader_lexicon\n",
    "!python3 -m nltk.downloader -d /Users/moiz/nltk_data punkt\n",
    "!python3 -m nltk.downloader -d /Users/moiz/nltk_data averaged_perceptron_tagger\n",
    "\n",
    "nltk.data.path.append('/Users/moiz/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy's English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "    clean_tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_stop]\n",
    "    return ' '.join(clean_tokens)\n",
    "\n",
    "# Load dataset\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "\n",
    "# Convert sentiments to numerical format\n",
    "y_train = train_df['sentiment'].map({'positive': 2, 'negative': 1}).astype(int)\n",
    "y_test = test_df['sentiment'].map({'positive': 2, 'negative': 1}).astype(int)\n",
    "\n",
    "# Define X_test\n",
    "X_test = test_df['review'] \n",
    "\n",
    "# Improved SentiWordNet analysis considering POS tags\n",
    "def get_wordnet_pos(spacy_token):\n",
    "    if spacy_token.pos_ in ('NOUN', 'PROPN'):\n",
    "        return wn.NOUN\n",
    "    elif spacy_token.pos_ == 'VERB':\n",
    "        return wn.VERB\n",
    "    elif spacy_token.pos_ == 'ADJ':\n",
    "        return wn.ADJ\n",
    "    elif spacy_token.pos_ == 'ADV':\n",
    "        return wn.ADV\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiwordnet_sentiment(review):\n",
    "    review = preprocess_text(review)\n",
    "    tokens = nlp(review)\n",
    "    pos_score = neg_score = 0\n",
    "    for token in tokens:\n",
    "        wn_tag = get_wordnet_pos(token)\n",
    "        if wn_tag:\n",
    "            synsets = list(swn.senti_synsets(token.text, wn_tag))\n",
    "            if synsets:\n",
    "                synset = synsets[0]\n",
    "                pos_score += synset.pos_score()\n",
    "                neg_score += synset.neg_score()\n",
    "    return 2 if pos_score > neg_score else 1\n",
    "\n",
    "# Afinn sentiment analysis\n",
    "afn = Afinn()\n",
    "def afinn_sentiment(review):\n",
    "    review = preprocess_text(review)\n",
    "    score = afn.score(review)\n",
    "    return 2 if score > 0 else 1\n",
    "\n",
    "# VADER sentiment analysis with adjusted threshold\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def vader_sentiment(review):\n",
    "    review = preprocess_text(review)\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    return 2 if scores['compound'] > 0.05 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentiWordNet Accuracy: 0.66455\n",
      "SentiWordNet Time: 1331.7760210037231 seconds\n"
     ]
    }
   ],
   "source": [
    "# Applying SentiWordNet sentiment analysis\n",
    "start = time.time()\n",
    "y_pred_swn = [sentiwordnet_sentiment(review) for review in X_test]\n",
    "end = time.time()\n",
    "accuracy_swn = accuracy_score(y_test, y_pred_swn)\n",
    "print(f'SentiWordNet Accuracy: {accuracy_swn}')\n",
    "print(f'SentiWordNet Time: {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afinn Accuracy: 0.7148\n",
      "Afinn Time: 985.3021380901337 seconds\n"
     ]
    }
   ],
   "source": [
    "# Applying Afinn sentiment analysis\n",
    "start = time.time()\n",
    "y_pred_afn = [afinn_sentiment(review) for review in X_test]\n",
    "end = time.time()\n",
    "accuracy_afn = accuracy_score(y_test, y_pred_afn)\n",
    "print(f'Afinn Accuracy: {accuracy_afn}')\n",
    "print(f'Afinn Time: {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Accuracy: 0.6772\n",
      "VADER Time: 935.612398147583 seconds\n"
     ]
    }
   ],
   "source": [
    "# Applying VADER sentiment analysis\n",
    "start = time.time()\n",
    "y_pred_vader = [vader_sentiment(review) for review in X_test]\n",
    "end = time.time()\n",
    "accuracy_vader = accuracy_score(y_test, y_pred_vader)\n",
    "print(f'VADER Accuracy: {accuracy_vader}')\n",
    "print(f'VADER Time: {end-start} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
