{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import ast\n",
    "import re\n",
    "import time\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')\n",
    "\n",
    "# Preprocess text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return tokens\n",
    "\n",
    "train_df['review'] = train_df['review'].apply(clean_text)\n",
    "test_df['review'] = test_df['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test datasets for Word2Vec training\n",
    "combined_reviews = pd.concat([train_df['review'], test_df['review']], axis=0)\n",
    "\n",
    "# Train Word2Vec model on combined data\n",
    "word2vec_model = Word2Vec(combined_reviews.tolist(), vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Save Word2Vec model\n",
    "word2vec_model.save(\"custom_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec.load(\"custom_word2vec.model\")\n",
    "\n",
    "# Function to create averaged word vectors\n",
    "def feature_vector(words, model):\n",
    "    featureVec = np.zeros((model.vector_size,), dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords += 1\n",
    "            featureVec = np.add(featureVec, model.wv[word])\n",
    "    if nwords > 0:\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n",
    "\n",
    "def get_avg_feature_vectors(reviews, model):\n",
    "    reviewFeatureVecs = np.zeros((len(reviews), model.vector_size), dtype=\"float32\")\n",
    "    for i, review in enumerate(reviews):\n",
    "        reviewFeatureVecs[i] = feature_vector(review, model)\n",
    "    return reviewFeatureVecs\n",
    "\n",
    "# Generate feature vectors for both train and test data\n",
    "trainDataVecs = get_avg_feature_vectors(train_df['review'], word2vec_model)\n",
    "testDataVecs = get_avg_feature_vectors(test_df['review'], word2vec_model)\n",
    "\n",
    "# Save feature vectors\n",
    "np.save('trainDataVecs.npy', trainDataVecs)\n",
    "np.save('testDataVecs.npy', testDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sentiment labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df['sentiment'])\n",
    "y_test = le.transform(test_df['sentiment'])\n",
    "\n",
    "# Save labels\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_evaluate_model(model, X_train, y_train, X_test, y_test, model_name='Model'):\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{model_name} Time: {end-start:.2f} seconds\")\n",
    "\n",
    "# Load feature vectors and labels for training\n",
    "X_train = np.load('trainDataVecs.npy')\n",
    "X_test = np.load('testDataVecs.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8310\n",
      "Random Forest Time: 30.65 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "train_evaluate_model(rf, X_train, y_train, X_test, y_test, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.7663\n",
      "Naive Bayes Time: 0.01 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "train_evaluate_model(gnb, X_train, y_train, X_test, y_test, 'Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy: 0.7994\n",
      "k-NN Time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "train_evaluate_model(knn, X_train, y_train, X_test, y_test, 'k-NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.8195\n",
      "Voting Classifier Time: 29.23 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create the Voting Classifier ensemble\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', rf), ('gnb', gnb), ('knn', knn)],\n",
    "    voting='hard')\n",
    "\n",
    "# Train and evaluate the Voting Classifier\n",
    "train_evaluate_model(voting_clf, X_train, y_train, X_test, y_test, 'Voting Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8500\n",
      "XGBoost Time: 19.01 seconds\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Train and evaluate XGBoost\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n",
    "train_evaluate_model(xgb_model, X_train, y_train, X_test, y_test, 'XGBoost')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
