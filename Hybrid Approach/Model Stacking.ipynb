{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from afinn import Afinn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Read the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Data/train.csv')\n",
    "test_df = pd.read_csv('Data/test.csv')\n",
    "\n",
    "reviews_train = train_df['review'].values\n",
    "sentiments_train = train_df['sentiment'].values\n",
    "reviews_test = test_df['review'].values\n",
    "sentiments_test = test_df['sentiment'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Define Lexicon-based Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to C:\\Users\\Abdullah\n",
      "[nltk_data]     Maqsood\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Abdullah\n",
      "[nltk_data]     Maqsood\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Abdullah Maqsood\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Abdullah\n",
      "[nltk_data]     Maqsood\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('sentiwordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def sentiwordnet_score(review):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentiment_score = 0\n",
    "\n",
    "    tokens = word_tokenize(review)\n",
    "    tagged = pos_tag(tokens)\n",
    "\n",
    "    for word, tag in tagged:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag is None:\n",
    "            continue\n",
    "\n",
    "        lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "        if not lemma:\n",
    "            continue\n",
    "\n",
    "        synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "        if not synsets:\n",
    "            continue\n",
    "\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "\n",
    "        sentiment_score += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "\n",
    "    return 'positive' if sentiment_score > 0 else 'negative'\n",
    "\n",
    "\n",
    "afinn = Afinn()\n",
    "\n",
    "def afinn_score(review):\n",
    "    score = afinn.score(review)\n",
    "    return 'positive' if score > 0 else 'negative'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Preprocess Data for ML Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(reviews_train)\n",
    "X_test_tfidf = vectorizer.transform(reviews_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Train Base Classifiers and Prepare Stacking Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize base classifiers\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Start time for base classifiers\n",
    "start_time_base = time.time()\n",
    "\n",
    "# Fit base classifiers\n",
    "gb_model.fit(X_train_tfidf, sentiments_train)\n",
    "knn_model.fit(X_train_tfidf, sentiments_train)\n",
    "\n",
    "# End time for base classifiers\n",
    "end_time_base = time.time()\n",
    "\n",
    "# Generate predictions for stacking features\n",
    "gb_predictions_train = gb_model.predict_proba(X_train_tfidf)[:, 1]\n",
    "knn_predictions_train = knn_model.predict_proba(X_train_tfidf)[:, 1]\n",
    "swn_predictions_train = np.array([sentiwordnet_score(review) for review in reviews_train])  \n",
    "afinn_predictions_train = np.array([afinn_score(review) for review in reviews_train]) \n",
    "\n",
    "# Stack predictions to create new feature set for the meta-classifier\n",
    "stacked_features_train = np.column_stack((gb_predictions_train, knn_predictions_train, swn_predictions_train, afinn_predictions_train))\n",
    "\n",
    "# Define a mapping between sentiment labels and numeric values\n",
    "sentiment_mapping = {'positive': 1, 'negative': 0}\n",
    "\n",
    "# Convert lexicon-based method predictions to numeric for the training set\n",
    "swn_predictions_train_numeric = np.array([sentiment_mapping[pred] for pred in swn_predictions_train])\n",
    "afinn_predictions_train_numeric = np.array([sentiment_mapping[pred] for pred in afinn_predictions_train])\n",
    "\n",
    "# Stack all numeric predictions to create new feature set for the meta-classifier\n",
    "stacked_features_train = np.column_stack((\n",
    "    gb_predictions_train, \n",
    "    knn_predictions_train, \n",
    "    swn_predictions_train_numeric, \n",
    "    afinn_predictions_train_numeric\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Train the Meta-classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the meta-classifier\n",
    "meta_classifier = LogisticRegression()\n",
    "\n",
    "# Start time for meta classifier\n",
    "start_time_meta = time.time()\n",
    "\n",
    "meta_classifier.fit(stacked_features_train, sentiments_train)\n",
    "\n",
    "# End time for meta classifier\n",
    "end_time_meta = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Prepare Test Features and Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking model accuracy: 0.8139\n",
      "Training time for base classifiers: 225.01136016845703 seconds\n",
      "Training time for meta classifier: 0.13895344734191895 seconds\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the test set\n",
    "gb_predictions_test = gb_model.predict_proba(X_test_tfidf)[:, 1]\n",
    "knn_predictions_test = knn_model.predict_proba(X_test_tfidf)[:, 1]\n",
    "swn_predictions_test = np.array([sentiwordnet_score(review) for review in reviews_test])  \n",
    "afinn_predictions_test = np.array([afinn_score(review) for review in reviews_test])  \n",
    "\n",
    "# Convert lexicon-based method predictions to numeric for the test set\n",
    "swn_predictions_test_numeric = np.array([sentiment_mapping[pred] for pred in swn_predictions_test])\n",
    "afinn_predictions_test_numeric = np.array([sentiment_mapping[pred] for pred in afinn_predictions_test])\n",
    "\n",
    "# Stack all numeric predictions to create new feature set for the meta-classifier\n",
    "stacked_features_test = np.column_stack((\n",
    "    gb_predictions_test, \n",
    "    knn_predictions_test, \n",
    "    swn_predictions_test_numeric, \n",
    "    afinn_predictions_test_numeric\n",
    "))\n",
    "\n",
    "# Predict using the meta-classifier\n",
    "final_predictions = meta_classifier.predict(stacked_features_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(sentiments_test, final_predictions)\n",
    "print(f'Stacking model accuracy: {accuracy}')\n",
    "\n",
    "print(f'Training time for base classifiers: {end_time_base - start_time_base} seconds')\n",
    "print(f'Training time for meta classifier: {end_time_meta - start_time_meta} seconds')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
